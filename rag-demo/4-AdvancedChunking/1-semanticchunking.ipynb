{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d350604",
   "metadata": {},
   "source": [
    "### Semantic Chunking\n",
    "\n",
    "- SemanticChunker is a document splitter that uses similarity between sentences to decide chunk boundaries.\n",
    "- It Ensures that each chunk is semantically coherent anf not cut off mid-thought like traditional character/token splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8bd88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167bf8e5",
   "metadata": {},
   "source": [
    "### 1.Document Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aaa2210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " chunk 1:\n",
      "Langchain is a framework for building applications with LLMs Langchain provides modular abstraction to combine LLMs with tools like OpenAI and Pinecone.\n",
      "\n",
      " chunk 2:\n",
      "You can create chains,agents,memory and retrievers\n",
      "\n",
      " chunk 3:\n",
      "The Eiffel Tower is located in Paris\n",
      "\n",
      " chunk 4:\n",
      "France is a popular tourist destination\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "## Sample text\n",
    "text = \"\"\" \n",
    "Langchain is a framework for building applications with LLMs\n",
    "Langchain provides modular abstraction to combine LLMs with tools like OpenAI and Pinecone.\n",
    "You can create chains,agents,memory and retrievers\n",
    "The Eiffel Tower is located in Paris\n",
    "France is a popular tourist destination\n",
    "\"\"\"\n",
    "\n",
    "# Step1: Split into Sentences\n",
    "\n",
    "sentences = [s.strip() for s in text.split(\"\\n\") if s.strip()]\n",
    "\n",
    "#Step2: Embed Each Sentence\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Step3: Initialize Parameters\n",
    "\n",
    "threshold = 0.7 # control chunk tightness\n",
    "chunks = []\n",
    "current_chunk = [sentences[0]]\n",
    "\n",
    "# Step4: Semantic grouping based on threshold\n",
    "for i in range(1, len(sentences)):\n",
    "    sim = cosine_similarity([embeddings[i-1]], [embeddings[i]])[0][0]\n",
    "    \n",
    "    if sim >= threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "    else:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk = [sentences[i]]\n",
    "\n",
    "# Append the last chunk\n",
    "chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "# Output\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"\\n chunk {idx+1}:\\n{chunk}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b943b",
   "metadata": {},
   "source": [
    "### Building RAG Pipeline With Semantic Chunker(Modular Coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5376fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8915d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad215cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### custom Semantic Chunker with threshold\n",
    "\n",
    "class ThresholdSemanticChunker:\n",
    "    def __init__(self,model_name=\"all-MiniLM-L6-v2\",threshold=0.7):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.threshold=threshold\n",
    "    \n",
    "    def split(self,text: str):\n",
    "        sentences = [s.strip() for s in text.split(\"\\n\") if s.strip()]\n",
    "        embeddings = self.model.encode(sentences) \n",
    "        chunks = []\n",
    "        current_chunk = [sentences[0]]\n",
    "\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim = cosine_similarity([embeddings[i-1]], [embeddings[i]])[0][0]\n",
    "            if sim >= self.threshold:\n",
    "                current_chunk.append(sentences[i])\n",
    "            else:\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk = [sentences[i]]\n",
    "\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        return chunks\n",
    "    \n",
    "    def split_documents(self,docs):\n",
    "        result=[]\n",
    "        for doc in docs:\n",
    "            for chunk in self.split(doc.page_content):\n",
    "                result.append(Document(page_content=chunk, metadata=doc.metadata))\n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd708b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content=' \\nLangchain is a framework for building applications with LLMs\\nLangchain provides modular abstraction to combine LLMs with tools like OpenAI and Pinecone.\\nYou can create chains,agents,memory and retrievers\\nThe Eiffel Tower is located in Paris\\nFrance is a popular tourist destination\\n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sample text\n",
    "sample_text = \"\"\" \n",
    "Langchain is a framework for building applications with LLMs\n",
    "Langchain provides modular abstraction to combine LLMs with tools like OpenAI and Pinecone.\n",
    "You can create chains,agents,memory and retrievers\n",
    "The Eiffel Tower is located in Paris\n",
    "France is a popular tourist destination\n",
    "\"\"\"\n",
    "\n",
    "doc = Document(page_content=sample_text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a37054a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Langchain is a framework for building applications with LLMs Langchain provides modular abstraction to combine LLMs with tools like OpenAI and Pinecone.'),\n",
       " Document(metadata={}, page_content='You can create chains,agents,memory and retrievers'),\n",
       " Document(metadata={}, page_content='The Eiffel Tower is located in Paris'),\n",
       " Document(metadata={}, page_content='France is a popular tourist destination')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chunking\n",
    "\n",
    "chunker = ThresholdSemanticChunker(threshold=0.7)\n",
    "chunks=chunker.split_documents([doc])\n",
    "chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d5faa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='sentence-transformers/all-MiniLM-L6-v2' cache_folder=None model_kwargs={} encode_kwargs={} query_encode_kwargs={} multi_process=False show_progress=False\n"
     ]
    }
   ],
   "source": [
    "### vectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "## Initialize HuggingFace Embeddings (No API Key Required)\n",
    "## First Train Your model\n",
    "hf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(hf_embeddings)\n",
    "\n",
    "vector_store=FAISS.from_documents(chunks,hf_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bae86424",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e142e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based in the following context:\\n\\n{context}\\n\\nQuestion: {question}\\n')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt template\n",
    "\n",
    "template = \"\"\"Answer the question based in the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1f8d09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, Langchain is a framework for building applications with Large Language Models (LLMs). It provides a modular abstraction to combine LLMs with tools like OpenAI and Pinecone.\n"
     ]
    }
   ],
   "source": [
    "llm = init_chat_model(model=\"groq:llama-3.1-8b-instant\",temperature=0.4)\n",
    "\n",
    "##LCEL Chain with retrieval\n",
    "\n",
    "rag_chain=(\n",
    "    RunnableMap(\n",
    "    {\n",
    "    \"context\": lambda x : retriever.invoke(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    ")\n",
    "| prompt\n",
    "| llm\n",
    "| StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "query = {\"question\": \"What is Langchain used for?\"}\n",
    "result = rag_chain.invoke(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c1ef0",
   "metadata": {},
   "source": [
    "### Semantic Chunker With Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4e97396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "436cd632",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m docs=loader.load()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m## Initialize Embedding model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m embeddings = \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m## Create the Semantic Chunker\u001b[39;00m\n\u001b[32m     13\u001b[39m chunker=SemanticChunker(embeddings)\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yaswa\\Downloads\\rag-demo\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:406\u001b[39m, in \u001b[36mOpenAIEmbeddings.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_async_client = httpx.AsyncClient(proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy)\n\u001b[32m    402\u001b[39m     async_specific = {\n\u001b[32m    403\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_async_client,\n\u001b[32m    404\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: async_api_key_value,\n\u001b[32m    405\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     \u001b[38;5;28mself\u001b[39m.async_client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43masync_specific\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.embeddings\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yaswa\\Downloads\\rag-demo\\.venv\\Lib\\site-packages\\openai\\_client.py:488\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    486\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    489\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    490\u001b[39m     )\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "## load the documents\n",
    "\n",
    "loader = TextLoader(\"langchain_intro.txt\")\n",
    "docs=loader.load()\n",
    "\n",
    "## Initialize Embedding model\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "## Create the Semantic Chunker\n",
    "\n",
    "chunker=SemanticChunker(embeddings)\n",
    "chunks = chunker.split_documents([docs])\n",
    "\n",
    "###\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n chunk {i+1}:\\n{chunk.page_content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
