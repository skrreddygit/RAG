{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Our API key is stored in environment variables\n",
    "from dotenv import load_dotenv # To load environment variables from a .env file\n",
    "load_dotenv() # Load environment variables from .env file\n",
    "OpenAI_api_key = os.getenv(\"OPEN_AI_KEY\") # To load the API key\n",
    "\n",
    "\n",
    "# To Set an API Key instead of loading from .env file\n",
    "os.environ[\"OPEN_AI_KEY\"] = \"your_openai_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7754769",
   "metadata": {},
   "source": [
    "### OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f1fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Single text embedding\n",
    "\n",
    "single_text = \"langchain is a framework for developing applications powered by language models\"\n",
    "single_text_embedding = embeddings.embed_query(single_text)\n",
    "print(single_text_embedding)\n",
    "\n",
    "\n",
    "print(f\"Output: vector of {len(single_text_embedding)} dimensions\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5156d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example2: Multiple text embeddings\n",
    "\n",
    "multiple_texts=[\"The Cat Sat on the mat\",\n",
    "           \"The dog sat on the log\",\n",
    "           \"Cats and dogs are great pets\",\n",
    "           \"I love to play football\",\n",
    "           \"Football is a great sport\"\n",
    "           \"Python is a programming language\",\n",
    "           \"I Love coding in Python\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_texts_embeddings = embeddings.embed_documents(multiple_texts)\n",
    "\n",
    "print(multiple_texts_embeddings)\n",
    "\n",
    "print(\"------------------------------------------------------\")\n",
    "print(f\"Number of texts: {len(multiple_texts)}\")\n",
    "print(f\"Number of embeddings generated: {len(multiple_texts_embeddings)}\")\n",
    "print(f\"Each embedding size is of dimension: {len(multiple_texts_embeddings[0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed759b4",
   "metadata": {},
   "source": [
    "### Cosine Similarity With OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79aaedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate the cosine similarity between two vectors.\n",
    "\n",
    "    Results close to 1 indicate high similarity,\n",
    "    while results close to -1 indicate low similarity/opposite direction.\n",
    "    0 indicates orthogonality (no similarity).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c66db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9617b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[\"The Cat Sat on the mat\",\n",
    "           \"The dog sat on the log\",\n",
    "           \"Cats and dogs are great pets\",\n",
    "           \"I love to play football\",\n",
    "           \"Football is a great sport\"\n",
    "           \"Python is a programming language\",\n",
    "           \"I Love coding in Python\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e943525",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_embeddings = embeddings.embed_documents(sentences)\n",
    "sentences_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between all pairs of sentence embeddings\n",
    "for i in range(len(sentences_embeddings)):\n",
    "    for j in range(i + 1, len(sentences_embeddings)):\n",
    "        similarity = cosine_similarity(sentences_embeddings[i], sentences_embeddings[j])\n",
    "        print(f\"Cosine Similarity between '{sentences[i]}' and '{sentences[j]}': {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Output: Semantic Search - retrieve the similar documents for a given query\n",
    "documents = [ \n",
    "    \"The cat sat on the mat.\",\n",
    "    \"Dogs are great pets.\",\n",
    "    \"I love playing football.\",\n",
    "    \"Python is a programming language.\",\n",
    "    \"Coding in Python is fun.\",\n",
    "   \"langchain is a framework for developing applications powered by language models\"]\n",
    "\n",
    "query = \"What is langchain?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71016644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, documents, embeddings, top_k=3):\n",
    "    \"\"\"Simple Semantic Search implementation.\"\"\"\n",
    "\n",
    "    ## Embed the query\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    # Embed the documents\n",
    "    document_embeddings = embeddings.embed_documents(documents)\n",
    "    # Calculate cosine similarities\n",
    "    similarities = []\n",
    "\n",
    "    for i, doc_emb in enumerate(document_embeddings):\n",
    "        sim = cosine_similarity(query_embedding, doc_emb)\n",
    "        similarities.append((i, sim))\n",
    "\n",
    "    # Sort by similarity score in descending order\n",
    "    similarities.sort(reverse=True)\n",
    "    # Get top_k results\n",
    "    return similarities[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = semantic_search(query, documents, embeddings)\n",
    "results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a5ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top similar documents:\")\n",
    "\n",
    "print(f\"\\n Semantic Search results for the query: '{query}'\")\n",
    "for score, doc in results:\n",
    "    print(f\"Score: {score:.3f} | {doc} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
